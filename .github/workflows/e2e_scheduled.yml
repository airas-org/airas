name: E2E Scheduled Test

on:
  schedule:
    # Run every Monday at 00:00 JST (Sunday 15:00 UTC)
    - cron: '0 15 * * 0'
  workflow_dispatch:
    inputs:
      research_topic:
        description: 'Research topic for the E2E test'
        required: false
        default: 'Proposing an improved Chain-of-Thought based on human thinking methods, evaluated purely through prompt tuning without fine-tuning or time-intensive experiments'
      is_github_repo_private:
        description: 'Make repository private'
        required: false
        type: boolean
        default: false
      github_owner:
        description: 'GitHub owner for the generated repository'
        required: false
        default: 'auto-res2'
      repository_name:
        description: 'Repository name (leave empty for auto-generated: e2e-test-YYYYMMDD-HHMMSS)'
        required: false
        default: ''
      branch_name:
        description: 'Branch name for the generated repository'
        required: false
        default: 'main'
      runner_label:
        description: 'Runner labels as JSON array (e.g., ["self-hosted", "gpu-runner"])'
        required: false
        default: '["self-hosted", "gpu-runner"]'
      runner_description:
        description: 'Runner description'
        required: false
        default: 'NVIDIA H200, VRAM: 140 GB, RAM: 240 GB'
      wandb_entity:
        description: 'W&B entity name'
        required: false
        default: 'airas'
      num_paper_search_queries:
        description: 'Number of search queries'
        required: false
        default: '3'
      papers_per_query:
        description: 'Number of papers retrieved per search query'
        required: false
        default: '5'
      hypothesis_refinement_iterations:
        description: 'Rounds of hypothesis refinement (novelty evaluation → refine loop)'
        required: false
        default: '2'
      num_experiment_models:
        description: 'Number of models to evaluate in experiments'
        required: false
        default: '1'
      num_experiment_datasets:
        description: 'Number of datasets to use in experiments'
        required: false
        default: '1'
      num_comparison_methods:
        description: 'Number of comparison methods'
        required: false
        default: '1'
      paper_content_refinement_iterations:
        description: 'Rounds of paper content refinement (write → refine loop)'
        required: false
        default: '1'
      latex_template_name:
        description: 'LaTeX template name (e.g., mdpi, iclr2024, agents4science_2025)'
        required: false
        default: 'mdpi'
      # --- LLM model settings ---
      primary_model:
        description: 'Primary LLM (query generation, hypothesis, design, analysis, writing, LaTeX)'
        required: false
        type: choice
        # NOTE: Use bare model names (e.g. "gemini-2.5-flash") for LangChainClient compatibility.
        # "provider/model" format (e.g. "google/gemini-2.5-flash") causes litellm.get_model_info() failures.
        options: &llm_options
          - 'gpt-5.2'
          - 'gpt-5.2-codex'
          - 'o3-2025-04-16'
          - 'o3-mini-2025-01-31'
          - 'gpt-5-mini-2025-08-07'
          - 'gemini-2.5-pro'
          - 'gemini-2.5-flash'
          - 'anthropic/claude-opus-4'
          - 'anthropic/claude-sonnet-4-5'
        default: 'gpt-5.2'
      paper_retrieval_model:
        description: 'Paper retrieval LLM (paper search, summarization, reference extraction)'
        required: false
        type: choice
        options: *llm_options
        default: 'gemini-2.5-flash'
      github_actions_agent:
        description: 'GitHub Actions agent tool (claude_code or open_code)'
        required: false
        type: choice
        options:
          - claude_code
          - open_code
        default: 'open_code'
      github_actions_model:
        description: 'GitHub Actions LLM (experiment dispatch, evaluation dispatch, LaTeX compilation)'
        required: false
        type: choice
        options: *llm_options
        default: 'anthropic/claude-sonnet-4-5'
      search_method:
        description: 'Paper search backend'
        required: false
        type: choice
        options:
          - airas_db
          - qdrant
        default: 'qdrant'

jobs:
  check-org-membership:
    runs-on: ubuntu-latest
    outputs:
      is_member: ${{ steps.check.outputs.is_member }}
    steps:
      - name: Check organization membership
        id: check
        env:
          GH_TOKEN: ${{ secrets.AIRAS_ORG_TOKEN }}
        run: |
          # For scheduled runs, always allow
          if [ "${{ github.event_name }}" = "schedule" ]; then
            echo "is_member=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          # For workflow_dispatch, check membership
          ACTOR="${{ github.actor }}"
          ORG="airas-org"

          echo "Checking if ${ACTOR} is a member of ${ORG}..."

          # Check membership using GitHub API
          HTTP_CODE=$(curl -s -o /dev/null -w "%{http_code}" \
            -H "Authorization: Bearer $GH_TOKEN" \
            -H "Accept: application/vnd.github+json" \
            "https://api.github.com/orgs/${ORG}/members/${ACTOR}")

          if [ "$HTTP_CODE" = "204" ]; then
            echo "✅ ${ACTOR} is a member of ${ORG}"
            echo "is_member=true" >> $GITHUB_OUTPUT
          else
            echo "❌ ${ACTOR} is not a member of ${ORG} (HTTP: ${HTTP_CODE})"
            echo "is_member=false" >> $GITHUB_OUTPUT
          fi

  e2e-test:
    needs: check-org-membership
    if: needs.check-org-membership.outputs.is_member == 'true'
    runs-on: ubicloud-standard-2
    timeout-minutes: 4320  # 72 hours

    services:
      db:
        image: postgres:16
        env:
          POSTGRES_USER: airas
          POSTGRES_PASSWORD: airas
          POSTGRES_DB: airas
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U airas -d airas"
          --health-interval 3s
          --health-timeout 3s
          --health-retries 20

    env:
      DATABASE_URL: postgresql+psycopg://airas:airas@localhost:5432/airas
      GH_PERSONAL_ACCESS_TOKEN: ${{ secrets.GH_PERSONAL_ACCESS_TOKEN }}

      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      AWS_BEARER_TOKEN_BEDROCK: ${{ secrets.AWS_BEARER_TOKEN_BEDROCK }}
      OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}

      QDRANT_API_KEY: ${{ secrets.QDRANT_API_KEY }}
      QDRANT_BASE_URL: ${{ secrets.QDRANT_BASE_URL }}
      WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
      HF_TOKEN: ${{ secrets.HF_TOKEN }}
      LANGFUSE_SECRET_KEY: ${{ secrets.LANGFUSE_SECRET_KEY }}
      LANGFUSE_PUBLIC_KEY: ${{ secrets.LANGFUSE_PUBLIC_KEY }}
      LANGFUSE_BASE_URL: ${{ secrets.LANGFUSE_BASE_URL }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          ref: develop

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: "0.7.2"

      - name: Set up Python
        run: uv python install 3.11

      - name: Install dependencies
        working-directory: backend
        run: uv sync --frozen

      - name: Install jq
        run: if ! command -v jq >/dev/null 2>&1; then sudo apt-get update -y && sudo apt-get install -y jq; fi

      - name: Start backend server
        working-directory: backend
        run: |
          mkdir -p /tmp/e2e-logs
          uv run uvicorn api.main:app --host 0.0.0.0 --port 8000 \
            > /tmp/e2e-logs/server.log 2>&1 &
          echo $! > /tmp/e2e-logs/server.pid
          echo "Server PID: $(cat /tmp/e2e-logs/server.pid)"
          echo "Waiting for server to start..."
          for i in {1..30}; do
            if curl -s http://localhost:8000/health > /dev/null 2>&1 || curl -s http://localhost:8000/ > /dev/null 2>&1; then
              echo "Server is ready!"
              break
            fi
            echo "Waiting... ($i/30)"
            sleep 2
          done

      - name: Generate dynamic parameters
        id: params
        run: |
          TIMESTAMP=$(date -u +"%Y%m%d-%H%M%S")
          DATE_ONLY=$(date -u +"%Y-%m-%d")

          # Use input repository_name if provided, otherwise generate
          INPUT_REPO_NAME="${{ github.event.inputs.repository_name }}"
          if [ -n "$INPUT_REPO_NAME" ]; then
            REPO_NAME="$INPUT_REPO_NAME"
          else
            REPO_NAME="e2e-test-${TIMESTAMP}"
          fi

          echo "timestamp=${TIMESTAMP}" >> $GITHUB_OUTPUT
          echo "date_only=${DATE_ONLY}" >> $GITHUB_OUTPUT
          echo "repo_name=${REPO_NAME}" >> $GITHUB_OUTPUT

      - name: Send E2E test request
        id: request
        run: |
          # === General parameters ===
          GITHUB_OWNER="${{ github.event.inputs.github_owner || 'auto-res2' }}"
          RESEARCH_TOPIC="${{ github.event.inputs.research_topic || 'Proposing an improved Chain-of-Thought based on human thinking methods, evaluated purely through prompt tuning without fine-tuning or time-intensive experiments' }}"
          BRANCH_NAME="${{ github.event.inputs.branch_name || 'main' }}"
          REPO_NAME="${{ steps.params.outputs.repo_name }}"
          WANDB_ENTITY="${{ github.event.inputs.wandb_entity || 'airas' }}"
          WANDB_PROJECT="${{ steps.params.outputs.timestamp }}"
          RUNNER_LABELS='${{ github.event.inputs.runner_label }}'
          RUNNER_DESC="${{ github.event.inputs.runner_description }}"
          if [ -z "$RUNNER_LABELS" ]; then
            RUNNER_LABELS='["self-hosted", "gpu-runner"]'
            RUNNER_DESC='NVIDIA H200, VRAM: 140 GB, RAM: 240 GB'
          fi
          IS_PRIVATE="${{ github.event.inputs.is_github_repo_private || 'false' }}"
          NUM_QUERIES="${{ github.event.inputs.num_paper_search_queries || '3' }}"
          PAPERS_PER_QUERY="${{ github.event.inputs.papers_per_query || '5' }}"
          HYPOTHESIS_ITERS="${{ github.event.inputs.hypothesis_refinement_iterations || '2' }}"
          NUM_MODELS="${{ github.event.inputs.num_experiment_models || '1' }}"
          NUM_DATASETS="${{ github.event.inputs.num_experiment_datasets || '1' }}"
          NUM_COMPARISONS="${{ github.event.inputs.num_comparison_methods || '1' }}"
          PAPER_REFINE_ITERS="${{ github.event.inputs.paper_content_refinement_iterations || '1' }}"
          LATEX_TEMPLATE="${{ github.event.inputs.latex_template_name || 'mdpi' }}"

          # === LLM model selections ===
          PRIMARY_MODEL="${{ github.event.inputs.primary_model || 'gpt-5.2' }}"
          PAPER_RETRIEVAL_MODEL="${{ github.event.inputs.paper_retrieval_model || 'gemini-2.5-flash' }}"
          GITHUB_ACTIONS_MODEL="${{ github.event.inputs.github_actions_model || 'anthropic/claude-sonnet-4-5' }}"
          GITHUB_ACTIONS_AGENT="${{ github.event.inputs.github_actions_agent || 'open_code' }}"

          # === Paper search settings ===
          SEARCH_METHOD="${{ github.event.inputs.search_method || 'qdrant' }}"

          # === Build LLM mapping JSON ===
          LLM_MAPPING=$(jq -n \
            --arg pm "$PRIMARY_MODEL" \
            --arg prm "$PAPER_RETRIEVAL_MODEL" \
            --arg gam "$GITHUB_ACTIONS_MODEL" \
            '{
              generate_queries: {generate_queries: {llm_name: $pm}},
              retrieve_paper: {
                search_arxiv_id_from_title: {llm_name: $prm},
                summarize_paper: {llm_name: $prm},
                extract_github_url_from_text: {llm_name: $prm},
                select_experimental_files: {llm_name: $prm},
                extract_reference_titles: {llm_name: $prm}
              },
              generate_hypothesis: {
                generate_hypothesis: {llm_name: $pm},
                evaluate_novelty_and_significance: {llm_name: $pm},
                refine_hypothesis: {llm_name: $pm}
              },
              generate_experimental_design: {generate_experimental_design: {llm_name: $pm}},
              dispatch_code_generation: {dispatch_code_generation: {llm_name: $gam}},
              dispatch_experiment_validation: {dispatch_experiment_validation: {llm_name: $gam}},
              analyze_experiment: {analyze_experiment: {llm_name: $pm}},
              write: {
                write_paper: {llm_name: $pm},
                refine_paper: {llm_name: $pm}
              },
              generate_latex: {convert_to_latex: {llm_name: $pm}},
              compile_latex: {compile_latex: {llm_name: $gam}}
            }')

          echo "Starting E2E test with:"
          echo "  Repository: ${GITHUB_OWNER}/${REPO_NAME}"
          echo "  Branch: ${BRANCH_NAME}"
          echo "  W&B: ${WANDB_ENTITY}/${WANDB_PROJECT}"
          echo "  Topic: ${RESEARCH_TOPIC}"
          echo "  LLM Mapping:"
          echo "$LLM_MAPPING" | head -30

          REQUEST_BODY=$(jq -n \
            --arg github_owner "$GITHUB_OWNER" \
            --arg repository_name "$REPO_NAME" \
            --arg branch_name "$BRANCH_NAME" \
            --arg research_topic "$RESEARCH_TOPIC" \
            --argjson runner_label "$RUNNER_LABELS" \
            --arg description "$RUNNER_DESC" \
            --arg wandb_entity "$WANDB_ENTITY" \
            --arg wandb_project "$WANDB_PROJECT" \
            --argjson is_github_repo_private "$IS_PRIVATE" \
            --arg search_method "$SEARCH_METHOD" \
            --argjson num_paper_search_queries "$NUM_QUERIES" \
            --argjson papers_per_query "$PAPERS_PER_QUERY" \
            --argjson hypothesis_refinement_iterations "$HYPOTHESIS_ITERS" \
            --argjson num_experiment_models "$NUM_MODELS" \
            --argjson num_experiment_datasets "$NUM_DATASETS" \
            --argjson num_comparison_methods "$NUM_COMPARISONS" \
            --argjson paper_content_refinement_iterations "$PAPER_REFINE_ITERS" \
            --arg latex_template_name "$LATEX_TEMPLATE" \
            --arg github_actions_agent "$GITHUB_ACTIONS_AGENT" \
            --argjson llm_mapping "$LLM_MAPPING" \
            '{
              github_config: {
                github_owner: $github_owner,
                repository_name: $repository_name,
                branch_name: $branch_name
              },
              research_topic: $research_topic,
              runner_config: {
                runner_label: $runner_label,
                description: $description
              },
              wandb_config: {
                entity: $wandb_entity,
                project: $wandb_project
              },
              is_github_repo_private: $is_github_repo_private,
              search_method: $search_method,
              num_paper_search_queries: $num_paper_search_queries,
              papers_per_query: $papers_per_query,
              hypothesis_refinement_iterations: $hypothesis_refinement_iterations,
              num_experiment_models: $num_experiment_models,
              num_experiment_datasets: $num_experiment_datasets,
              num_comparison_methods: $num_comparison_methods,
              paper_content_refinement_iterations: $paper_content_refinement_iterations,
              latex_template_name: $latex_template_name,
              github_actions_agent: $github_actions_agent,
              llm_mapping: $llm_mapping
            }')

          RESPONSE=$(curl -s -w "\n%{http_code}" -X POST http://localhost:8000/airas/v1/topic_open_ended_research/run \
            -H "Content-Type: application/json" \
            -d "$REQUEST_BODY")

          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          BODY=$(echo "$RESPONSE" | sed '$d')

          echo "Response (HTTP ${HTTP_CODE}):"
          echo "$BODY" | jq . || echo "$BODY"

          if [ "$HTTP_CODE" -ge 200 ] && [ "$HTTP_CODE" -lt 300 ]; then
            echo "✅ E2E test request sent successfully"
            TASK_ID=$(echo "$BODY" | jq -r '.task_id')
            echo "task_id=${TASK_ID}" >> $GITHUB_OUTPUT
          else
            echo "❌ E2E test request failed with HTTP ${HTTP_CODE}"
            exit 1
          fi

      - name: Poll for task completion
        run: |
          TASK_ID="${{ steps.request.outputs.task_id }}"
          echo "Polling task ${TASK_ID} ..."

          START_TIME=$(date +%s)
          POLL_COUNT=0
          STEP_POLL_COUNT=0
          CONSECUTIVE_ERRORS=0
          MAX_CONSECUTIVE_ERRORS=10
          PREV_STEP=""

          # Progressive interval; resets on step transition.
          get_poll_interval() {
            local n=$1
            if [ "$n" -le 10 ]; then echo 30
            elif [ "$n" -le 30 ]; then echo 60
            elif [ "$n" -le 60 ]; then echo 120
            elif [ "$n" -le 120 ]; then echo 300
            else echo 600; fi
          }

          while true; do
            POLL_COUNT=$((POLL_COUNT + 1))
            STEP_POLL_COUNT=$((STEP_POLL_COUNT + 1))
            ELAPSED=$(( $(date +%s) - START_TIME ))

            STATUS_RESPONSE=$(curl -s -w "\n%{http_code}" \
              "http://localhost:8000/airas/v1/topic_open_ended_research/status/${TASK_ID}")
            STATUS_HTTP=$(echo "$STATUS_RESPONSE" | tail -n1)
            STATUS_BODY=$(echo "$STATUS_RESPONSE" | sed '$d')

            if [ "$STATUS_HTTP" -ne 200 ]; then
              CONSECUTIVE_ERRORS=$((CONSECUTIVE_ERRORS + 1))
              echo "[Poll #${POLL_COUNT}] HTTP ${STATUS_HTTP} (error ${CONSECUTIVE_ERRORS}/${MAX_CONSECUTIVE_ERRORS})"
              echo "--- Error response body ---"
              echo "$STATUS_BODY" | jq . 2>/dev/null || echo "$STATUS_BODY"
              echo "--- Server log (last 20 lines) ---"
              tail -n 20 /tmp/e2e-logs/server.log 2>/dev/null || echo "(no log)"
              echo "---"
              if [ "$CONSECUTIVE_ERRORS" -ge "$MAX_CONSECUTIVE_ERRORS" ]; then
                echo "ABORT: Too many consecutive HTTP errors"
                tail -n 100 /tmp/e2e-logs/server.log 2>/dev/null || true
                exit 1
              fi
              POLL_INTERVAL=$(get_poll_interval $STEP_POLL_COUNT)
              sleep $POLL_INTERVAL
              continue
            fi
            CONSECUTIVE_ERRORS=0

            TASK_STATUS=$(echo "$STATUS_BODY" | jq -r '.status')
            CURRENT_STEP=$(echo "$STATUS_BODY" | jq -r '.current_step // "N/A"')
            ERROR_MSG=$(echo "$STATUS_BODY" | jq -r '.error_message // empty')

            # Reset interval on step transition
            if [ "$CURRENT_STEP" != "$PREV_STEP" ] && [ -n "$PREV_STEP" ]; then
              STEP_POLL_COUNT=0
              # Ensure next poll after a step change uses the shortest interval
              POLL_INTERVAL=30
            else
              POLL_INTERVAL=$(get_poll_interval $STEP_POLL_COUNT)
            fi
            PREV_STEP="$CURRENT_STEP"

            echo "[Poll #${POLL_COUNT} | ${ELAPSED}s] ${TASK_STATUS} - ${CURRENT_STEP}"
            echo "--- Status response ---"
            echo "$STATUS_BODY" | jq 'del(.result, .research_history)'
            echo "--- Server log (last 20 lines) ---"
            tail -n 20 /tmp/e2e-logs/server.log 2>/dev/null || echo "(no log)"
            echo "---"

            if [ "$TASK_STATUS" = "completed" ]; then
              echo "E2E test completed (${ELAPSED}s)"
              exit 0
            fi

            if [ "$TASK_STATUS" = "failed" ] || [ -n "$ERROR_MSG" ]; then
              echo "E2E test failed: ${ERROR_MSG}"
              echo "--- Server log (last 100 lines) ---"
              tail -n 100 /tmp/e2e-logs/server.log 2>/dev/null || true
              exit 1
            fi

            if [ "$TASK_STATUS" != "pending" ] && [ "$TASK_STATUS" != "running" ]; then
              echo "❌ Unexpected task status: ${TASK_STATUS}"
              exit 1
            fi

            sleep $POLL_INTERVAL
          done

      - name: Upload server logs
        if: always()
        uses: actions/upload-artifact@v6
        with:
          name: e2e-server-logs-${{ steps.params.outputs.timestamp }}
          path: /tmp/e2e-logs/
          retention-days: 30
