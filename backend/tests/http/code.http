### Dispatch code generation
POST http://127.0.0.1:8000/airas/v1/code/generations/dispatch
Content-Type: application/json

{
    "github_config": {
        "github_owner": "auto-res2",
        "repository_name": "matsuzawa-2026-02-10",
        "branch_name": "main"
    },
    "research_topic": "Improving Chain-of-Thought reasoning with cycle-consistent grounding",
    "github_actions_agent": "open_code",
    "llm_mapping": {
        "dispatch_code_generation": {
            "llm_name": "anthropic/claude-sonnet-4-5"
        }
    },
    "research_hypothesis": {
        "open_problems": "Auto-CoT-style pipelines still lack a label-free way to detect \"plausible but ungrounded\" demonstrations: a CoT can be (i) internally consistent under resampling and (ii) stable under paraphrases, yet still be mis-anchored—it solves a subtly different problem than the question actually asks (entity/quantity confusion, implicit assumption injection, or paraphrase drift). This failure mode is especially dangerous in social uses (tutoring/decision support) because the rationale looks coherent and repeatable, so it is likely to be trusted and then copied by in-context learning.\n\nKey gap: How can we estimate whether a candidate demonstration's reasoning is not only stable, but also grounded to the original question semantics, using only the same base LLM and cheap post-processing—no labels, no verifier model, no training?",
        "method": "Cycle-Consistent & Paraphrase-Invariant Reliability Auto-CoT (C3-AutoCoT)\n\nRefine PIR-AutoCoT by adding a third \"human checking\" axis: can I reconstruct the problem I solved from my own explanation?\n\nC3-AutoCoT modifies only the demo construction stage (clustering and downstream prompting remain Auto-CoT).\n\nFor each candidate demo question q:\n1) Re-derive (within-question self-consistency): sample m CoT chains on q → answers A(q). Compute r_sc = max_a freq(a in A(q))/m.\n2) Rephrase (paraphrase invariance): generate p paraphrases with the same LLM; filter paraphrases that drift by requiring the multiset of numbers in q_i to match q. For each q_i sample m chains → answers A(q_i). Compute r_pi = mean_i P(answer=a* | q_i).\n3) Reconstruct (cycle-consistency / grounding): Take a representative chain c* for q that yields a*. Ask the LLM to reconstruct the original word problem given c*: q_hat = f_reconstruct(c*). Compute grounding score r_cc = 0.5·cos_sim(emb(q_hat), emb(q)) + 0.5·I(numbers(q_hat)=numbers(q)).\n\nCombined demo reliability: r = r_sc · r_pi · r_cc.\nAccept demo if r ≥ τ and at least one paraphrase survives the number-preservation filter.",
        "experimental_setup": "Tasks/Datasets: SVAMP (fast arithmetic word problems), GSM8K (stronger but heavier)\n\nModels: google/flan-t5-base (primary), google/flan-t5-large (robustness)\n\nCompared methods (same k demos, same evaluation):\n1) Zero-shot-CoT (no demos)\n2) Auto-CoT (cluster + single chain + heuristics)\n3) RW-AutoCoT (self-consistency demo filter)\n4) PIR-AutoCoT (self-consistency + paraphrase invariance)\n5) C3-AutoCoT (proposed)\n\nProtocol:\n- Demo pool: first 500 train questions\n- Clustering: SentenceTransformer embeddings + k-means (k=8)\n- For each cluster, consider up to T=10 candidates until a demo is accepted\n- Evaluation: N=200 test questions; greedy decoding\n- Seeds: 3 seeds (k-means init + sampling)\n\nHyperparameters:\n- m=4 samples per variant\n- p=2 paraphrases\n- reconstruction samples=1 (deterministic)\n- τ=0.25–0.40",
        "primary_metric": "accuracy",
        "experimental_code": "import re, random\nimport numpy as np\nfrom collections import Counter\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.cluster import KMeans\n\nnum_re = re.compile(r\"-?\\d+(?:\\.\\d+)?\")\n\ndef extract_numbers(s: str):\n    return num_re.findall(s)\n\ndef extract_final_number(text: str):\n    nums = extract_numbers(text)\n    return nums[-1] if nums else None\n\ndef agreement_rate(answers):\n    answers = [a for a in answers if a is not None]\n    if not answers:\n        return 0.0, None\n    c = Counter(answers)\n    maj, ct = c.most_common(1)[0]\n    return ct / len(answers), maj\n\n@torch.inference_mode()\ndef generate_texts(model, tok, prompt, n=1, do_sample=True, temperature=0.7, max_new_tokens=256):\n    inp = tok(prompt, return_tensors='pt', truncation=True).to(model.device)\n    outs = model.generate(\n        **inp,\n        do_sample=do_sample,\n        temperature=temperature if do_sample else None,\n        top_p=0.95 if do_sample else None,\n        num_return_sequences=n,\n        max_new_tokens=max_new_tokens,\n    )\n    return tok.batch_decode(outs, skip_special_tokens=True)\n\nif __name__ == \"__main__\":\n    print(\"C3-AutoCoT implementation scaffold\")\n",
        "expected_result": "On SVAMP (200-example test subset) with flan-t5-base, k=8 demos, m=4, p=2:\n- Auto-CoT: 0.20–0.28 accuracy\n- RW-AutoCoT: 0.23–0.32\n- PIR-AutoCoT: 0.27–0.36\n- C3-AutoCoT (proposed): 0.30–0.40\n\nExpected gains:\n- C3 vs Auto-CoT: +0.07 to +0.12\n- C3 vs PIR-AutoCoT: +0.02 to +0.05\n\nHigher is better.",
        "expected_conclusion": "C3-AutoCoT strengthens Auto-CoT with a cognitively inspired triple-check that better matches human verification: (1) re-derive (self-consistency), (2) rephrase (paraphrase invariance), and (3) reconstruct (cycle-consistency grounding). This targets a sharper and more socially relevant failure mode than PIR alone: demonstrations that are stable yet solve a different problem than asked."
    },
    "experimental_design": {
        "experiment_summary": "Task: Solve elementary arithmetic word problems by generating a chain-of-thought (CoT) rationale and a final numeric answer.\n\nPurpose: Demonstrate that C3-AutoCoT yields higher downstream problem-solving accuracy than PIR-AutoCoT by filtering out \"plausible but ungrounded\" candidate demonstrations during the demo construction stage.\n\nCore workflow:\n1) Demo pool: first 500 SVAMP training questions\n2) Clustering: SentenceTransformer embeddings + k-means (k=8)\n3) Demo selection: For each cluster, accept candidate demo if r=r_sc·r_pi·r_cc≥τ\n4) Evaluation: 200 test questions with fixed 8-demo prompt, greedy decoding",
        "evaluation_metrics": [
            {
            "name": "accuracy",
            "description": "End-task correctness: proportion of test questions with correct final numeric answer. Extract predicted answer as last number in output; compare with gold answer."
            },
            {
            "name": "demo_acceptance_rate",
            "description": "Fraction of clusters that successfully accepted a demo candidate within top-T attempts."
            },
            {
            "name": "mean_reliability_components",
            "description": "Average values of r_sc (self-consistency), r_pi (paraphrase invariance), r_cc (cycle-consistency grounding) across accepted demos."
            },
            {
            "name": "grounding_utility_correlation",
            "description": "Correlation between r_cc and downstream accuracy per cluster (does grounding predict usefulness?)."
            }
        ],
        "models_to_use": ["Qwen3-8B (8B parameters)"],
        "datasets_to_use": ["SVAMP (MU-NLPC/Calc-svamp)"],
        "proposed_method": {
            "method_name": "C3-AutoCoT (Cycle-Consistent & Paraphrase-Invariant Reliability Auto-CoT)",
            "description": "Inference-only enhancement to Auto-CoT demonstration construction. Estimate demo reliability along three label-free axes: (1) within-question self-consistency (r_sc), (2) paraphrase invariance with number-preservation filter (r_pi), and (3) cycle-consistency grounding (r_cc). Accept demo if r=r_sc·r_pi·r_cc≥τ."
        },
        "comparative_methods": [
            {
            "method_name": "PIR-AutoCoT (Paraphrase-Invariant Reliability Auto-CoT)",
            "description": "Baseline that filters demos based on (1) within-question self-consistency and (2) paraphrase invariance. Does not include cycle-consistency grounding. Reliability: r=r_sc·r_pi."
            }
        ]
    },
    "wandb_config": {
        "entity": "airas",
        "project": "2026-02-10-test"
    }
}

###
    "research_hypothesis": {
        "open_problems": "Auto-CoT-style pipelines still lack a label-free way to detect \"plausible but ungrounded\" demonstrations: a CoT can be (i) internally consistent under resampling and (ii) stable under paraphrases, yet still be mis-anchored—it solves a subtly different problem than the question actually asks (entity/quantity confusion, implicit assumption injection, or paraphrase drift). This failure mode is especially dangerous in social uses (tutoring/decision support) because the rationale looks coherent and repeatable, so it is likely to be trusted and then copied by in-context learning.\n\nKey gap: How can we estimate whether a candidate demonstration's reasoning is not only stable, but also grounded to the original question semantics, using only the same base LLM and cheap post-processing—no labels, no verifier model, no training?",
        "method": "Cycle-Consistent & Paraphrase-Invariant Reliability Auto-CoT (C3-AutoCoT)\n\nRefine PIR-AutoCoT by adding a third \"human checking\" axis: can I reconstruct the problem I solved from my own explanation?\n\nC3-AutoCoT modifies only the demo construction stage (clustering and downstream prompting remain Auto-CoT).\n\nFor each candidate demo question q:\n1) Re-derive (within-question self-consistency): sample m CoT chains on q → answers A(q). Compute r_sc = max_a freq(a in A(q))/m.\n2) Rephrase (paraphrase invariance): generate p paraphrases with the same LLM; filter paraphrases that drift by requiring the multiset of numbers in q_i to match q. For each q_i sample m chains → answers A(q_i). Compute r_pi = mean_i P(answer=a* | q_i).\n3) Reconstruct (cycle-consistency / grounding): Take a representative chain c* for q that yields a*. Ask the LLM to reconstruct the original word problem given c*: q_hat = f_reconstruct(c*). Compute grounding score r_cc = 0.5·cos_sim(emb(q_hat), emb(q)) + 0.5·I(numbers(q_hat)=numbers(q)).\n\nCombined demo reliability: r = r_sc · r_pi · r_cc.\nAccept demo if r ≥ τ and at least one paraphrase survives the number-preservation filter.",
        "experimental_setup": "Tasks/Datasets: SVAMP (fast arithmetic word problems), GSM8K (stronger but heavier)\n\nModels: google/flan-t5-base (primary), google/flan-t5-large (robustness)\n\nCompared methods (same k demos, same evaluation):\n1) Zero-shot-CoT (no demos)\n2) Auto-CoT (cluster + single chain + heuristics)\n3) RW-AutoCoT (self-consistency demo filter)\n4) PIR-AutoCoT (self-consistency + paraphrase invariance)\n5) C3-AutoCoT (proposed)\n\nProtocol:\n- Demo pool: first 500 train questions\n- Clustering: SentenceTransformer embeddings + k-means (k=8)\n- For each cluster, consider up to T=10 candidates until a demo is accepted\n- Evaluation: N=200 test questions; greedy decoding\n- Seeds: 3 seeds (k-means init + sampling)\n\nHyperparameters:\n- m=4 samples per variant\n- p=2 paraphrases\n- reconstruction samples=1 (deterministic)\n- τ=0.25–0.40",
        "primary_metric": "accuracy",
        "experimental_code": "import re, random\nimport numpy as np\nfrom collections import Counter\n\nimport torch\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.cluster import KMeans\n\nnum_re = re.compile(r\"-?\\d+(?:\\.\\d+)?\")\n\ndef extract_numbers(s: str):\n    return num_re.findall(s)\n\ndef extract_final_number(text: str):\n    nums = extract_numbers(text)\n    return nums[-1] if nums else None\n\ndef agreement_rate(answers):\n    answers = [a for a in answers if a is not None]\n    if not answers:\n        return 0.0, None\n    c = Counter(answers)\n    maj, ct = c.most_common(1)[0]\n    return ct / len(answers), maj\n\n@torch.inference_mode()\ndef generate_texts(model, tok, prompt, n=1, do_sample=True, temperature=0.7, max_new_tokens=256):\n    inp = tok(prompt, return_tensors='pt', truncation=True).to(model.device)\n    outs = model.generate(\n        **inp,\n        do_sample=do_sample,\n        temperature=temperature if do_sample else None,\n        top_p=0.95 if do_sample else None,\n        num_return_sequences=n,\n        max_new_tokens=max_new_tokens,\n    )\n    return tok.batch_decode(outs, skip_special_tokens=True)\n\nif __name__ == \"__main__\":\n    print(\"C3-AutoCoT implementation scaffold\")\n",
        "expected_result": "On SVAMP (200-example test subset) with flan-t5-base, k=8 demos, m=4, p=2:\n- Auto-CoT: 0.20–0.28 accuracy\n- RW-AutoCoT: 0.23–0.32\n- PIR-AutoCoT: 0.27–0.36\n- C3-AutoCoT (proposed): 0.30–0.40\n\nExpected gains:\n- C3 vs Auto-CoT: +0.07 to +0.12\n- C3 vs PIR-AutoCoT: +0.02 to +0.05\n\nHigher is better.",
        "expected_conclusion": "C3-AutoCoT strengthens Auto-CoT with a cognitively inspired triple-check that better matches human verification: (1) re-derive (self-consistency), (2) rephrase (paraphrase invariance), and (3) reconstruct (cycle-consistency grounding). This targets a sharper and more socially relevant failure mode than PIR alone: demonstrations that are stable yet solve a different problem than asked."
    },
    "experimental_design": {
        "experiment_summary": "Task: Solve elementary arithmetic word problems by generating a chain-of-thought (CoT) rationale and a final numeric answer.\n\nPurpose: Demonstrate that C3-AutoCoT yields higher downstream problem-solving accuracy than PIR-AutoCoT by filtering out \"plausible but ungrounded\" candidate demonstrations during the demo construction stage.\n\nCore workflow:\n1) Demo pool: first 500 SVAMP training questions\n2) Clustering: SentenceTransformer embeddings + k-means (k=8)\n3) Demo selection: For each cluster, accept candidate demo if r=r_sc·r_pi·r_cc≥τ\n4) Evaluation: 200 test questions with fixed 8-demo prompt, greedy decoding",
        "evaluation_metrics": [
            {
            "name": "accuracy",
            "description": "End-task correctness: proportion of test questions with correct final numeric answer. Extract predicted answer as last number in output; compare with gold answer."
            },
            {
            "name": "demo_acceptance_rate",
            "description": "Fraction of clusters that successfully accepted a demo candidate within top-T attempts."
            },
            {
            "name": "mean_reliability_components",
            "description": "Average values of r_sc (self-consistency), r_pi (paraphrase invariance), r_cc (cycle-consistency grounding) across accepted demos."
            },
            {
            "name": "grounding_utility_correlation",
            "description": "Correlation between r_cc and downstream accuracy per cluster (does grounding predict usefulness?)."
            }
        ],
        "models_to_use": ["Qwen3-8B (8B parameters)"],
        "datasets_to_use": ["SVAMP (MU-NLPC/Calc-svamp)"],
        "proposed_method": {
            "method_name": "C3-AutoCoT (Cycle-Consistent & Paraphrase-Invariant Reliability Auto-CoT)",
            "description": "Inference-only enhancement to Auto-CoT demonstration construction. Estimate demo reliability along three label-free axes: (1) within-question self-consistency (r_sc), (2) paraphrase invariance with number-preservation filter (r_pi), and (3) cycle-consistency grounding (r_cc). Accept demo if r=r_sc·r_pi·r_cc≥τ."
        },
        "comparative_methods": [
            {
            "method_name": "PIR-AutoCoT (Paraphrase-Invariant Reliability Auto-CoT)",
            "description": "Baseline that filters demos based on (1) within-question self-consistency and (2) paraphrase invariance. Does not include cycle-consistency grounding. Reliability: r=r_sc·r_pi."
            }
        ]
    },
### Fetch experiment code
POST http://127.0.0.1:8000/airas/v1/code/fetch
Content-Type: application/json

{
    "github_config": {
        "github_owner": "auto-res2",
        "repository_name": "matsuzawa-2026-02-10",
        "branch_name": "main"
    }
}

###
